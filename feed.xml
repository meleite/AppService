<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en_US"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://azure.github.io/AppService/feed.xml" rel="self" type="application/atom+xml" /><link href="https://azure.github.io/AppService/" rel="alternate" type="text/html" hreflang="en_US" /><updated>2024-11-29T00:12:12+00:00</updated><id>https://azure.github.io/AppService/feed.xml</id><title type="html">Azure App Service</title><subtitle>Announcements, updates, and release notes from the Azure App Service product team.</subtitle><author><name>Azure App Service</name></author><entry><title type="html">.NET 9 GA available on Azure App Service</title><link href="https://azure.github.io/AppService/2024/11/12/dotnet9-ga.html" rel="alternate" type="text/html" title=".NET 9 GA available on Azure App Service" /><published>2024-11-12T00:00:00+00:00</published><updated>2024-11-12T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/11/12/dotnet9-ga</id><content type="html" xml:base="https://azure.github.io/AppService/2024/11/12/dotnet9-ga.html"><![CDATA[<p>We have completed the rollout for <a href="https://dotnet.microsoft.com/download/dotnet/9.0">.NET 9 GA</a> support on Azure App Service.</p>

<p>Like in previous years we are using the <a href="https://aka.ms/app-service-early-access">App Service Early Access feature</a> to enable day-0 support on the platform across all public regions on Azure App Service for Windows. The early access release will be followed by additional deployments to fully integrate the new bits across our fleet, expecting to be fully done by the end of the week.</p>

<p>On Azure App Service for Linux, .NET 9 GA will be fully integrated on day-0 across all public regions without any additional deployments.</p>

<p>If you already have an app targeting an earlier preview of .NET 9.0 on the platform for App Service for Windows, you would need to redeploy the application after updating your <a href="https://learn.microsoft.com/en-us/dotnet/core/runtime-config/">runtimeconfig.json</a> to use .NET 9.0.0.</p>

<p>For Azure App Service for Linux, if you already have an app targeting an earlier preview of .NET 9.0 on the platform, there is no need to take action as the new runtime will be picked up on the next application restart once the update is available for your app. You can trigger this manually by stopping and starting your app.</p>

<p>Self-contained .NET apps will <em>not</em> be auto-updated since they have no dependency on the runtime provided by App Service.</p>

<p>Azure Functions and Azure Static Webapps are also enabling .NET 9 workloads across their scenarios.</p>

<p>If you want to learn more, be sure to checkout our sessions during <a href="https://www.dotnetconf.net/agenda">.NET Conf 2024</a>:</p>
<ul>
  <li>Check out all the new features of .NET 9 announced on <a href="https://www.youtube.com/watch?v=hM4ifrqF_lQ">.NET Conf 2024 - Day 1</a></li>
  <li>Wednesday 11/13 @ 9:00am PST Join <a href="https://twitter.com/coolcsh">Scott Hunter</a> and <a href="https://x.com/paulyuki99">Paul Yuknewicz</a> to learn more about “Building and scaling cloud-native, intelligent applications on Azure and .NET”.</li>
  <li>Friday 11/15 @ 8:30 AM PST Jeff Martinez will show you how to build secure Intelligent apps in the session “Secure intelligent apps with .NET 9 on App Service”</li>
</ul>

<p>You can also checkout all the new Azure App Service features and capabilities that we are announcing at <a href="https://ignite.microsoft.com/sessions?filter=topic%2FlogicalValue%3EApps">Ignite 2024</a></p>

<p>Next steps:</p>

<ul>
  <li><a href="https://dotnet.microsoft.com/download/dotnet/9.0">Download .NET 9</a></li>
  <li><a href="https://devblogs.microsoft.com/dotnet/announcing-dotnet-9/">Anouncing .NET 9</a></li>
  <li><a href="https://learn.microsoft.com/aspnet/core/release-notes/aspnetcore-9.0">ASP.NET Core in .NET 9</a></li>
  <li><a href="https://learn.microsoft.com/azure/app-service/quickstart-dotnetcore?tabs=net80&amp;pivots=development-environment-vs">Deploy a .NET application to App Service</a></li>
</ul>

<p>You can also follow us on twitter for more updates and news: <a href="https://twitter.com/AzAppService/">@AzAppService</a></p>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[We have completed the rollout for .NET 9 GA support on Azure App Service.]]></summary></entry><entry><title type="html">Announcing inbound IPv6 support in public preview</title><link href="https://azure.github.io/AppService/2024/11/08/Announcing-Inbound-IPv6-support.html" rel="alternate" type="text/html" title="Announcing inbound IPv6 support in public preview" /><published>2024-11-08T00:00:00+00:00</published><updated>2024-11-08T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/11/08/Announcing-Inbound-IPv6-support</id><content type="html" xml:base="https://azure.github.io/AppService/2024/11/08/Announcing-Inbound-IPv6-support.html"><![CDATA[<p>Update 2 - November 8, 2024: IPv6 non-vnet outbound support is rolling out soon. We expect public preview to begin in late Q1 2025. Azure portal support to set the <code class="language-plaintext highlighter-rouge">IPMode</code> property is now available. A screenshot is included below.</p>

<p>Update 1 - August 1, 2024: All but two regions are now supported and we have Azure portal support rolling out soon. We also added a CLI sample for configuration IPv6 support on a deployment slot.</p>

<h2 id="introduction">Introduction</h2>

<p>I am happy to announce the first part of our IPv6 implementation in App Service. Public preview of inbound IPv6 support for multi-tenant apps on Premium SKUs, Functions Consumption, Functions Elastic Premium, and Logic Apps Standard. We’ll be adding IPv6 support in four stages.</p>

<ol>
  <li>This announcement: IPv6 inbound support (multi-tenant)</li>
  <li>In development: IPv6 non-vnet outbound support (multi-tenant)</li>
  <li>Backlog: IPv6 vnet outbound support (multi-tenant and App Service Environment v3)</li>
  <li>Backlog: IPv6 vnet inbound support (App Service Environment v3 - both internal and external)</li>
</ol>

<p>Limitations in this public preview:</p>

<ul>
  <li>Only a subset of regions are supported - see the list below.</li>
  <li>Basic and Standard tier currently does not support changing the <code class="language-plaintext highlighter-rouge">IPMode</code> property.</li>
  <li>Functions Consumption may have multiple IP addresses in the DNS result.</li>
  <li>Functions Consumption and Elastic Premium may not remove the IPv4 address in IPv6 mode.</li>
  <li>The IPv6 address is not visible in the <code class="language-plaintext highlighter-rouge">inboundIpAddress</code> or <code class="language-plaintext highlighter-rouge">possibleInboundIpAddresses</code> properties.</li>
  <li>IP-SSL IPv6 bindings are not supported.</li>
</ul>

<p>For GA we will work on including Basic and Standard tier, adding all regions, include the IPv6 addresses in new properties and stabilize the DNS results to not show extra addresses.</p>

<h2 id="how-does-it-work">How does it work</h2>

<p>IPv6 inbound requires two things: an IPv6 address that accepts traffic coming in, and a DNS record that returns an IPv6 (AAAA) record. You’ll also need a client that can send and receive IPv6 traffic. This means that you may not be able to test it from your local machine since many networks today only support IPv4.</p>

<p>Our stamps (deployment units) will all have IPv6 addresses added. When these are added, you can start sending traffic to both the IPv4 and IPv6 address. To ensure backwards compatibility, the DNS response for the default host name (<em>app-name</em>.azurewebsites.net) will return only the IPv4 address. If you want to change that, we have added a site property called <code class="language-plaintext highlighter-rouge">IPMode</code> that you can configure to <code class="language-plaintext highlighter-rouge">IPv6</code> or <code class="language-plaintext highlighter-rouge">IPv4AndIPv6</code>. If you set it to IPv6 only, your client will need to “understand” IPv6 in order to get a response. Setting it to IPv4 and IPv6 will allow you to have existing clients use IPv4, but allow capable clients to use IPv6. If your client does support IPv6, you can test the IPv6 connection using curl:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-6</span> https://&lt;app-name&gt;.azurewebsites.net
</code></pre></div></div>

<p>If you are using custom domain, you can define your custom DNS records the same way. If you only add an IPv6 (AAAA) record, your clients will need to support IPv6. You can also choose to add both, and finally you can use a CNAME to the default hostname of the site in which case you will use the behavior of <code class="language-plaintext highlighter-rouge">IPMode</code>.</p>

<p>Do make a note of some of the limitations and especially behavior of Functions plans. We will be working on fixing those issues before General Availability. Do also note that DNS tends to have multiple layers of caching, and sometimes it can take 5-10 minutes for DNS to return the right records.</p>

<h2 id="update-using-cli">Update using CLI</h2>

<p>To update an app to return IPv6 DNS records:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az resource update <span class="nt">--name</span> &lt;app-name&gt; <span class="nt">--set</span> properties.ipMode<span class="o">=</span><span class="s2">"IPv6"</span> <span class="nt">-g</span> &lt;resource-group-name&gt; <span class="nt">--resource-type</span> <span class="s2">"Microsoft.Web/sites"</span>
</code></pre></div></div>

<p>If you are updating a slot, you’ll need the resource id of the slot. Here is an example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>az resource update <span class="nt">--ids</span> <span class="s1">'/subscriptions/&lt;sub-id&gt;/resourceGroups/&lt;resource-group-name&gt;/providers/Microsoft.Web/sites/&lt;app-name&gt;/slots/&lt;slot-name&gt;'</span> <span class="nt">--set</span> properties.ipMode<span class="o">=</span><span class="s1">'IPv6'</span>
</code></pre></div></div>

<h2 id="update-using-azure-portal">Update using Azure portal</h2>

<p>To update an app to return IPv6 DNS records, you can use the Azure portal. Go to the app, and under the <strong>Configuration</strong> blade, you’ll find the <code class="language-plaintext highlighter-rouge">Inbound IP mode (preview)</code> property.</p>

<p><img src="/AppService/media/2024/11/ipmode.png" alt="Inbound IP mode portal setting" /></p>

<h2 id="create-or-update-using-azure-resource-manager-templates">Create or update using Azure Resource Manager templates</h2>

<p>To deploy a new app or update an existing app using ARM, you can just set the IPMode to either IPv6 or IPv4AndIPv6. In this template, you are also creating an App Service plan. If you use the template below, replace the values prefixed with REPLACE. For the <code class="language-plaintext highlighter-rouge">reserved</code> property, true = Linux, false = Windows.</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
    <span class="dl">"</span><span class="s2">$schema</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">contentVersion</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">1.0.0.0</span><span class="dl">"</span><span class="p">,</span>
    <span class="dl">"</span><span class="s2">variables</span><span class="dl">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="dl">"</span><span class="s2">appName</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">REPLACE-APP-NAME</span><span class="dl">"</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">appIPMode</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">IPv6</span><span class="dl">"</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">appServicePlanName</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">REPLACE-PLAN-NAME</span><span class="dl">"</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">appServicePlanSize</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">P1v3</span><span class="dl">"</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">appServicePlanInstanceCount</span><span class="dl">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">location</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[resourceGroup().location]</span><span class="dl">"</span>
    <span class="p">},</span>
    <span class="dl">"</span><span class="s2">resources</span><span class="dl">"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="dl">"</span><span class="s2">name</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[variables('appServicePlanName')]</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">type</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">Microsoft.Web/serverfarms</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">apiVersion</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">2021-03-01</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">location</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[variables('location')]</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">properties</span><span class="dl">"</span><span class="p">:</span> <span class="p">{</span>
                <span class="dl">"</span><span class="s2">reserved</span><span class="dl">"</span><span class="p">:</span> <span class="kc">false</span>
            <span class="p">},</span>
            <span class="dl">"</span><span class="s2">sku</span><span class="dl">"</span><span class="p">:</span> <span class="p">{</span>
                <span class="dl">"</span><span class="s2">name</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[variables('appServicePlanSize')]</span><span class="dl">"</span><span class="p">,</span>
                <span class="dl">"</span><span class="s2">capacity</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[variables('appServicePlanInstanceCount')]</span><span class="dl">"</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="dl">"</span><span class="s2">name</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[variables('appName')]</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">type</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">Microsoft.Web/sites</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">apiVersion</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">2021-03-01</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">location</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[variables('location')]</span><span class="dl">"</span><span class="p">,</span>
            <span class="dl">"</span><span class="s2">dependsOn</span><span class="dl">"</span><span class="p">:</span> <span class="p">[</span>
                <span class="dl">"</span><span class="s2">[resourceId('Microsoft.Web/serverfarms', variables('appServicePlanName'))]</span><span class="dl">"</span>
            <span class="p">],</span>
            <span class="dl">"</span><span class="s2">properties</span><span class="dl">"</span><span class="p">:</span> <span class="p">{</span>
              <span class="dl">"</span><span class="s2">serverFarmId</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[resourceId('Microsoft.Web/serverfarms', variables('appServicePlanName'))]</span><span class="dl">"</span><span class="p">,</span>
              <span class="dl">"</span><span class="s2">httpsOnly</span><span class="dl">"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
              <span class="dl">"</span><span class="s2">ipMode</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">[variables('appIPMode')]</span><span class="dl">"</span>
            <span class="p">}</span>
        <span class="p">}</span>
     <span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="supported-regions">Supported regions</h2>

<p>This is the current list of supported regions in preview.</p>

<table>
  <thead>
    <tr>
      <th>Region</th>
      <th style="text-align: center">IPv6 supported</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Australia Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Australia Central 2</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Australia East</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Australia Southeast</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Brazil South</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Brazil Southeast</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Canada Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Canada East</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Central India</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Central US</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>East Asia</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>East US</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>East US 2</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>France Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>France South</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Germany North</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Germany West Central</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td>Italy North</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Japan East</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Japan West</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Jio India West</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Korea Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Korea South</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>North Central US</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>North Europe</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Norway East</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Norway West</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Poland Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Qatar Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>South Africa North</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>South Africa West</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>South Central US</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>South India</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Southeast Asia</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Sweden Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Switzerland North</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>Switzerland West</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>UAE Central</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>UAE North</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>UK South</td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td>UK West</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>West Central US</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>West Europe</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>West India</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>West US</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>West US 2</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
    <tr>
      <td>West US 3</td>
      <td style="text-align: center">:heavy_check_mark:</td>
    </tr>
  </tbody>
</table>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[Update 2 - November 8, 2024: IPv6 non-vnet outbound support is rolling out soon. We expect public preview to begin in late Q1 2025. Azure portal support to set the IPMode property is now available. A screenshot is included below.]]></summary></entry><entry><title type="html">Introducing Sidecars for Azure App Service for Linux: Now Generally Available</title><link href="https://azure.github.io/AppService/2024/11/08/Global-Availability-Sidecars.html" rel="alternate" type="text/html" title="Introducing Sidecars for Azure App Service for Linux: Now Generally Available" /><published>2024-11-08T00:00:00+00:00</published><updated>2024-11-08T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/11/08/Global-Availability-Sidecars</id><content type="html" xml:base="https://azure.github.io/AppService/2024/11/08/Global-Availability-Sidecars.html"><![CDATA[<p>The <strong>sidecar pattern</strong> is an architectural approach that allows you to deploy components of an application in separate processes or containers, providing both isolation and encapsulation. This pattern is particularly useful for applications needing to be composed of diverse components and technologies, including new capabilities and integrations. <a href="https://techcommunity.microsoft.com/blog/appsonazureblog/announcing-the-general-availability-of-sidecar-extensibility-in-azure-app-servic/4267985">Learn more about how you can use sidecar extensibility to modernize your applications</a></p>

<h2 id="benefits-of-using-the-sidecar-extensibility-on-azure-app-service-for-linux">Benefits of Using the sidecar extensibility on Azure App Service for Linux</h2>

<p>The sidecar pattern enables applications to expand functionality seamlessly. By adding sidecars, you can introduce a variety of capabilities to enhance your application, including:</p>

<ul>
  <li><strong>Observability</strong>: Integrate monitoring and observability tools to gain insights into application performance without modifying your core application code.</li>
  <li><strong>Caching</strong>: Improve response times and performance by adding caching services as a sidecar component.</li>
  <li><strong>AI Features</strong>: Add artificial intelligence capabilities, such as language models or machine learning models, in a sidecar to process or augment application data.</li>
</ul>

<h2 id="availability">Availability</h2>

<p>Sidecars for Azure App Service for Linux is now <strong>generally available</strong> across all public regions. This feature supports both <strong>code-based applications</strong> and <strong>container-based applications</strong>.</p>

<ul>
  <li><strong>For code-based apps</strong>: You can configure sidecars using Azure Resource Manager (ARM) templates. Here is a sample <a href="https://github.com/Azure-Samples/sidecar-samples/tree/main/sidecar-arm-template">ARM template</a> that you can use. <a href="https://learn.microsoft.com/en-us/azure/app-service/quickstart-arm-template?pivots=platform-linux">Learn more about using ARM templates to create App Service App</a>
    <blockquote>
      <p><em>Note</em>: Portal support for this feature is being gradually rolled out. This documentation will be updated once the rollout is complete. We expect the rollout to be completed by Januray, 2025.</p>
    </blockquote>
  </li>
  <li><strong>For container-based apps</strong>: Get started by following this <a href="https://learn.microsoft.com/en-us/azure/app-service/tutorial-custom-container-sidecar">custom container tutorial</a> on deploying a sidecar for your containerized application.</li>
</ul>

<h2 id="learn-more">Learn More</h2>

<p>To explore scenarios where sidecars can add value, including observability, caching, and AI-based enhancements, please refer to the following resources:</p>

<ul>
  <li>Enhancing Observability with <a href="https://azure.github.io/AppService/2024/07/26/Using-Datadog-with-Sidecar.html">Datadog</a> and <a href="https://azure.github.io/AppService/2024/07/26/Using-Dynatrace-with-Sidecar.html">Dynatrace</a></li>
  <li><a href="https://azure.github.io/AppService/2024/07/19/Using-Redis-with-Sidecar.html">Improving application performance with Redis sidecar</a></li>
  <li><a href="https://azure.github.io/AppService/2024/09/03/Phi3-vector.html">Integrating AI Capabilities Using Sidecars</a></li>
</ul>

<p>With sidecars for Linux App Service, you can effectively modernize applications and build new ones that leverage distributed, heterogeneous components, enhancing both flexibility and scalability.</p>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[The sidecar pattern is an architectural approach that allows you to deploy components of an application in separate processes or containers, providing both isolation and encapsulation. This pattern is particularly useful for applications needing to be composed of diverse components and technologies, including new capabilities and integrations. Learn more about how you can use sidecar extensibility to modernize your applications]]></summary></entry><entry><title type="html">How to pull from ACR with Managed Identity using Windows containers</title><link href="https://azure.github.io/AppService/2024/09/17/How-to-pull-from-ACR-with-Managed-Identity-using-Windows-containers.html" rel="alternate" type="text/html" title="How to pull from ACR with Managed Identity using Windows containers" /><published>2024-09-17T00:00:00+00:00</published><updated>2024-09-17T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/09/17/How-to-pull-from-ACR-with-Managed-Identity-using-Windows-containers</id><content type="html" xml:base="https://azure.github.io/AppService/2024/09/17/How-to-pull-from-ACR-with-Managed-Identity-using-Windows-containers.html"><![CDATA[<p>Managed identities offer a way to secure communications between Azure resources without having to manage any credentials. The following are the steps to enable <strong>system-assigned</strong> identity when pulling from Azure Container Registry (ACR) with the use of a Windows container application.</p>

<h3 id="prerequisites">Prerequisites</h3>

<ol>
  <li><a href="https://learn.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest">Azure CLI version</a> (version 2.6.3 or above) to configure your resources. If you don’t want to install the Azure CLI locally, you can use the <a href="https://learn.microsoft.com/en-us/azure/cloud-shell/get-started/classic?tabs=azurecli">Azure Cloud Shell</a></li>
  <li>A containerized .NET web app published to Azure Container Registry</li>
</ol>

<h3 id="assign-an-identity-to-your-app">Assign an identity to your app</h3>

<p>Using the <code class="language-plaintext highlighter-rouge">az</code> commands below, assign the system-assigned identity to your application. You will need the following information:</p>

<ol>
  <li>Resource group name: “groupName”</li>
  <li>Web app name: “appName”</li>
</ol>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="w"> </span><span class="nx">webapp</span><span class="w"> </span><span class="nx">create</span><span class="w"> </span><span class="nt">--resource-group</span><span class="w"> </span><span class="err">&lt;</span><span class="nx">groupName</span><span class="err">&gt;</span><span class="w"> </span><span class="nt">--name</span><span class="w"> </span><span class="err">&lt;</span><span class="nx">appName</span><span class="err">&gt;</span><span class="w"> </span><span class="nt">--container-image-name</span><span class="w"> </span><span class="nx">myacr.azurecr.io/myimage:mytag</span><span class="w"> </span><span class="nt">--assign-identity</span><span class="w"> </span><span class="p">[</span><span class="n">system</span><span class="p">]</span><span class="w"> </span><span class="nt">--acr-use-identity</span><span class="w"> </span><span class="nt">--acr-identity</span><span class="w"> </span><span class="p">[</span><span class="n">system</span><span class="p">]</span><span class="w">
</span></code></pre></div></div>

<p>This command will return a json output that shows all your configuration settings. You will also notice the identity “type” is set to “SystemAssigned” in the returned output. From here, you can also view your updated registry settings in the Azure portal Deployment Center of your Web App resource.</p>

<p>Now that the identity is assigned, we can grab the principal and registry Id’s to use in creating the role assignment. Run the following commands to query and store the necessary Id’s:</p>

<h4 id="principal-identity-id">Principal identity Id</h4>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Principal_Id</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">az</span><span class="w"> </span><span class="nx">webapp</span><span class="w"> </span><span class="nx">identity</span><span class="w"> </span><span class="nx">show</span><span class="w"> </span><span class="nt">-g</span><span class="w"> </span><span class="err">&lt;</span><span class="nx">groupName</span><span class="err">&gt;</span><span class="w"> </span><span class="nt">-p</span><span class="w"> </span><span class="err">&lt;</span><span class="nx">planName</span><span class="err">&gt;</span><span class="w"> </span><span class="nt">-n</span><span class="w"> </span><span class="err">&lt;</span><span class="nx">appName</span><span class="err">&gt;</span><span class="w"> </span><span class="nt">--query</span><span class="w"> </span><span class="nx">principalId</span><span class="w"> </span><span class="nt">--output</span><span class="w"> </span><span class="nx">tsv</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h4 id="registry-resource-id">Registry resource Id</h4>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Registry_Id</span><span class="o">=</span><span class="err">$</span><span class="p">(</span><span class="n">az</span><span class="w"> </span><span class="nx">acr</span><span class="w"> </span><span class="nx">show</span><span class="w"> </span><span class="nt">-g</span><span class="w"> </span><span class="err">&lt;</span><span class="nx">groupName</span><span class="err">&gt;</span><span class="w"> </span><span class="nt">-n</span><span class="w"> </span><span class="err">&lt;</span><span class="nx">registryName</span><span class="err">&gt;</span><span class="w"> </span><span class="nt">--query</span><span class="w"> </span><span class="nx">id</span><span class="w"> </span><span class="nt">--output</span><span class="w"> </span><span class="nx">tsv</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<h3 id="create-role-assignment">Create role assignment</h3>

<p>Once the Id’s are queried and stored, you can create the role assignment to pull from ACR.</p>

<p>Run the following command to create the role assignment:</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">az</span><span class="w"> </span><span class="nx">role</span><span class="w"> </span><span class="nx">assignment</span><span class="w"> </span><span class="nx">create</span><span class="w"> </span><span class="nt">--assignee</span><span class="w"> </span><span class="nv">$Principal_Id</span><span class="w"> </span><span class="nt">--scope</span><span class="w"> </span><span class="nv">$Registry_Id</span><span class="w"> </span><span class="nt">--role</span><span class="w"> </span><span class="s2">"AcrPull"</span><span class="w">
</span></code></pre></div></div>

<p>Once ran, the output will include a json of the identity parameters and their values. You can also check your enabled access in the Azure portal by going to the registry resource:</p>

<ol>
  <li>Navigate to the Access control (IAM) blade on the left side</li>
  <li>Click on the Role assignments tab</li>
  <li>Search for your app name used in the previous cli commands</li>
</ol>

<p>You should see your app resource with a role of “AcrPull”. Now that this is set, you are ready to pull images from a container registry using System-assigned Managed Identity.</p>]]></content><author><name>Azure App Service</name></author><category term="dotnet" /><category term="windows containers" /><summary type="html"><![CDATA[Managed identities offer a way to secure communications between Azure resources without having to manage any credentials. The following are the steps to enable system-assigned identity when pulling from Azure Container Registry (ACR) with the use of a Windows container application.]]></summary></entry><entry><title type="html">Azure App Service Community Standup: .NET 9 and App Configuration</title><link href="https://azure.github.io/AppService/2024/09/04/App-Service-Community-Standup.html" rel="alternate" type="text/html" title="Azure App Service Community Standup: .NET 9 and App Configuration" /><published>2024-09-04T00:00:00+00:00</published><updated>2024-09-04T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/09/04/App-Service-Community-Standup</id><content type="html" xml:base="https://azure.github.io/AppService/2024/09/04/App-Service-Community-Standup.html"><![CDATA[<p>Watch the latest Azure App Service Community Standup on .NET 9 and App Configuration</p>

<p><a href="https://www.youtube.com/watch?v=Vj2ujuj5_Vo"><img src="https://img.youtube.com/vi/Vj2ujuj5_Vo/hqdefault.jpg" alt="Azure App Service Community Standup" /></a></p>

<p>For more information on .NET 9 and App Configuration on App Service, check out the following resources:</p>

<ul>
  <li>
    <p><a href="https://azure.microsoft.com/updates/v2/app-config-ref-ga">Generally Available: App Configuration references on App Service</a></p>
  </li>
  <li>
    <p><a href="https://learn.microsoft.com/azure/app-service/app-service-configuration-references">Use App Configuration references - Azure App Service</a></p>
  </li>
  <li>
    <p><a href="https://azure.github.io/AppService/2024/08/19/net-9-preview-6-available-on-app-service.html">NET 9 Preview 6 now available on App Service</a></p>
  </li>
  <li>
    <p><a href="https://learn.microsoft.com/dotnet/core/whats-new/dotnet-9/overview">What’s New in .NET 9</a></p>
  </li>
</ul>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[Watch the latest Azure App Service Community Standup on .NET 9 and App Configuration]]></summary></entry><entry><title type="html">Implementing Local RAG using Phi-3 ONNX Runtime and Sidecar Pattern on Linux App Service</title><link href="https://azure.github.io/AppService/2024/09/03/Phi3-vector.html" rel="alternate" type="text/html" title="Implementing Local RAG using Phi-3 ONNX Runtime and Sidecar Pattern on Linux App Service" /><published>2024-09-03T00:00:00+00:00</published><updated>2024-09-03T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/09/03/Phi3-vector</id><content type="html" xml:base="https://azure.github.io/AppService/2024/09/03/Phi3-vector.html"><![CDATA[<p>In our previous post, <a href="https://azure.github.io/AppService/2024/08/19/Phi-3-ONNX.html">“Phi-3 ONNX: Leveraging the Power of ONNX Runtime to Run SLM on CPU”</a>, we explored how to deploy and run the Phi-3 ONNX Runtime model on Linux App Service, enabling sophisticated language model capabilities without the need for a GPU. Building on that foundation, this blog post will take you through the implementation of Retrieval-Augmented Generation (RAG) using local resources.</p>

<p>To recap, Retrieval-Augmented Generation (RAG) is a hybrid approach that enhances the capabilities of a language model by incorporating external knowledge. This technique combines the strengths of traditional retrieval systems and generative models to provide more accurate and contextually relevant responses. In our case, we’re applying this concept to build an intelligent Assistant for our Fashion Store.</p>

<p>The Assistant we’re creating utilizes external knowledge stored in several markdown (.md) files. These files contain essential information about our store’s products, as well as shipping, payment, and exchange policies. The Assistant will leverage this knowledge to answer customer queries with relevance.</p>

<p>Our sample application is composed of two main components:</p>

<ol>
  <li>
    <p><strong>Frontend Chat Application</strong>: Built using Python Flask, this serves as the user interface where customers can interact with the Assistant.</p>
  </li>
  <li>
    <p><strong>Backend Application</strong>: Developed in .NET, this application loads the markdown files into an in-memory vector database. Upon receiving a query, the backend performs a search within the vector database and passes the search results as context to the Phi-3 model. The generated response is then streamed back to the chat client.</p>
  </li>
</ol>

<p>For the in-memory vector database, we’re using <a href="https://github.com/Build5Nines/SharpVector">Build5Nines.SharpVector</a>, an excellent open-source project by <a href="https://pietschsoft.com/">Chris Pietschmann</a>. SharpVector makes it easy to store and retrieve vectorized data, making it an ideal choice for our sample RAG implementation.</p>

<p>It’s important to note that this setup is designed for demo purposes. For building enterprise-scale applications, you may need to consider using distributed solutions like Cosmos DB or other scalable data storage and retrieval systems to handle larger datasets and more complex operations.</p>

<h3 id="prerequisites">Prerequisites</h3>

<p>To build and run this demo, ensure you have the following:</p>

<ul>
  <li><strong>.NET 8 SDK</strong>: Required for the backend application. <a href="https://dotnet.microsoft.com/download/dotnet/8.0">Download .NET 8</a>.</li>
  <li><strong>Visual Studio Code (VS Code)</strong>: For editing and developing project files. <a href="https://code.visualstudio.com/">Get VS Code</a>.</li>
  <li><strong>Docker Desktop</strong>: Necessary for containerizing the applications. <a href="https://www.docker.com/products/docker-desktop">Install Docker</a>.</li>
  <li><strong>Python 3.9 or higher</strong>: Used for the Python Flask frontend. <a href="https://www.python.org/downloads/">Download Python</a>.</li>
  <li><strong>Git</strong>: To clone the sample repository. <a href="https://git-scm.com/downloads">Get Git</a>.</li>
</ul>

<p>Clone the sidecar samples repository to get started:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/Azure-Samples/sidecar-samples
</code></pre></div></div>

<h3 id="setting-up-the-net-backend">Setting Up the .NET Backend</h3>

<p>Once you have cloned the application, you’ll find the code for the backend in the <code class="language-plaintext highlighter-rouge">phi3-vector-api</code> directory. This backend is responsible for loading and processing the markdown files into an in-memory vector database and then generating responses using the Phi-3 ONNX model. Most of the key logic is contained within the <code class="language-plaintext highlighter-rouge">PhiController.cs</code> file, which you can view <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/phi3-vector/phi3-vector-api/Controllers/Phi3Controller.cs">here</a>.</p>

<h4 id="key-dependencies">Key Dependencies</h4>

<p>We’ve added three important packages to the project:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="nn">Build5Nines.SharpVector</span><span class="p">;</span>
<span class="k">using</span> <span class="nn">Build5Nines.SharpVector.Data</span><span class="p">;</span>
<span class="k">using</span> <span class="nn">Microsoft.ML.OnnxRuntimeGenAI</span><span class="p">;</span>
</code></pre></div></div>

<p>These packages enable us to work with vector databases and integrate the ONNX runtime for AI-based generation.</p>

<h4 id="loading-the-model-and-creating-the-tokenizer">Loading the Model and Creating the Tokenizer</h4>

<p>The model is loaded from the filesystem, and a tokenizer is created to handle text processing:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_model</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">Model</span><span class="p">(</span><span class="s">"/app/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4"</span><span class="p">);</span>
<span class="n">_tokenizer</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">Tokenizer</span><span class="p">(</span><span class="n">_model</span><span class="p">);</span>
</code></pre></div></div>

<h4 id="loading-documents-into-the-vector-database">Loading Documents into the Vector Database</h4>

<p>Next, we load all the <code class="language-plaintext highlighter-rouge">.md</code> files from the local filesystem into the in-memory vector database. In this demo, we’re using paragraph chunking, which breaks the text into paragraphs. However, you could opt for other chunking methods, such as line-based or character limit chunking:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">private</span> <span class="k">async</span> <span class="n">Task</span> <span class="nf">LoadAdditionalDocuments</span><span class="p">(</span><span class="kt">string</span> <span class="n">directoryPath</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">var</span> <span class="n">files</span> <span class="p">=</span> <span class="n">Directory</span><span class="p">.</span><span class="nf">GetFiles</span><span class="p">(</span><span class="n">directoryPath</span><span class="p">,</span> <span class="s">"*.*"</span><span class="p">,</span> <span class="n">SearchOption</span><span class="p">.</span><span class="n">AllDirectories</span><span class="p">)</span>
                         <span class="p">.</span><span class="nf">Where</span><span class="p">(</span><span class="n">f</span> <span class="p">=&gt;</span> <span class="n">f</span><span class="p">.</span><span class="nf">EndsWith</span><span class="p">(</span><span class="s">".txt"</span><span class="p">,</span> <span class="n">StringComparison</span><span class="p">.</span><span class="n">OrdinalIgnoreCase</span><span class="p">)</span> <span class="p">||</span>
                                     <span class="n">f</span><span class="p">.</span><span class="nf">EndsWith</span><span class="p">(</span><span class="s">".md"</span><span class="p">,</span> <span class="n">StringComparison</span><span class="p">.</span><span class="n">OrdinalIgnoreCase</span><span class="p">)</span> <span class="p">||</span>
                                     <span class="n">f</span><span class="p">.</span><span class="nf">EndsWith</span><span class="p">(</span><span class="s">".mdx"</span><span class="p">,</span> <span class="n">StringComparison</span><span class="p">.</span><span class="n">OrdinalIgnoreCase</span><span class="p">)).</span><span class="nf">ToArray</span><span class="p">();</span>

    <span class="kt">var</span> <span class="n">vectorDataLoader</span> <span class="p">=</span> <span class="k">new</span> <span class="n">TextDataLoader</span><span class="p">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">string</span><span class="p">&gt;(</span><span class="n">_vectorDatabase</span><span class="p">);</span>
    <span class="kt">var</span> <span class="n">tasks</span> <span class="p">=</span> <span class="n">files</span><span class="p">.</span><span class="nf">Select</span><span class="p">(</span><span class="k">async</span> <span class="n">file</span> <span class="p">=&gt;</span>
    <span class="p">{</span>
        <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">$"Loading </span><span class="p">{</span><span class="n">file</span><span class="p">}</span><span class="s">"</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">System</span><span class="p">.</span><span class="n">IO</span><span class="p">.</span><span class="n">File</span><span class="p">.</span><span class="nf">Exists</span><span class="p">(</span><span class="n">file</span><span class="p">))</span>
        <span class="p">{</span>
            <span class="kt">var</span> <span class="n">fileContents</span> <span class="p">=</span> <span class="k">await</span> <span class="n">System</span><span class="p">.</span><span class="n">IO</span><span class="p">.</span><span class="n">File</span><span class="p">.</span><span class="nf">ReadAllTextAsync</span><span class="p">(</span><span class="n">file</span><span class="p">);</span>
            <span class="k">await</span> <span class="n">vectorDataLoader</span><span class="p">.</span><span class="nf">AddDocumentAsync</span><span class="p">(</span><span class="n">fileContents</span><span class="p">,</span> <span class="k">new</span> <span class="n">TextChunkingOptions</span><span class="p">&lt;</span><span class="kt">string</span><span class="p">&gt;</span>
            <span class="p">{</span>
                <span class="n">Method</span> <span class="p">=</span> <span class="n">TextChunkingMethod</span><span class="p">.</span><span class="n">Paragraph</span><span class="p">,</span>
                <span class="n">RetrieveMetadata</span> <span class="p">=</span> <span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="p">=&gt;</span> <span class="n">file</span>
            <span class="p">});</span>
        <span class="p">}</span>
    <span class="p">});</span>

    <span class="k">await</span> <span class="n">Task</span><span class="p">.</span><span class="nf">WhenAll</span><span class="p">(</span><span class="n">tasks</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="generating-responses">Generating Responses</h4>

<p>When a user sends a query, we search the vector database for relevant information and use that as context for generating a response with the Phi-3 model. The response is then streamed back to the client as it’s generated:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="nf">HttpPost</span><span class="p">(</span><span class="s">"generate-response"</span><span class="p">)]</span>
<span class="k">public</span> <span class="k">async</span> <span class="n">Task</span> <span class="nf">GenerateResponse</span><span class="p">([</span><span class="n">FromBody</span><span class="p">]</span> <span class="kt">string</span> <span class="n">userPrompt</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"Generate method called with : "</span> <span class="p">+</span> <span class="n">userPrompt</span><span class="p">);</span>
    <span class="kt">string</span> <span class="n">resultText</span> <span class="p">=</span> <span class="k">await</span> <span class="nf">SearchVectorDatabase</span><span class="p">(</span><span class="n">_vectorDatabase</span><span class="p">,</span> <span class="n">userPrompt</span><span class="p">);</span>
    <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"Vector search returned : "</span> <span class="p">+</span> <span class="n">resultText</span><span class="p">);</span>
    <span class="kt">var</span> <span class="n">fullPrompt</span> <span class="p">=</span> <span class="s">$"</span><span class="p">{</span><span class="n">_systemPrompt</span><span class="p">}</span><span class="s">\n\n</span><span class="p">{</span><span class="n">resultText</span><span class="p">}</span><span class="s">\n\n</span><span class="p">{</span><span class="n">userPrompt</span><span class="p">}</span><span class="s">"</span><span class="p">;</span>

    <span class="n">Response</span><span class="p">.</span><span class="n">ContentType</span> <span class="p">=</span> <span class="s">"text/plain"</span><span class="p">;</span>
    <span class="k">await</span> <span class="k">foreach</span> <span class="p">(</span><span class="kt">var</span> <span class="n">token</span> <span class="k">in</span> <span class="nf">GenerateAiResponse</span><span class="p">(</span><span class="n">fullPrompt</span><span class="p">))</span>
    <span class="p">{</span>
        <span class="k">if</span><span class="p">(</span><span class="n">token</span> <span class="p">==</span> <span class="k">null</span> <span class="p">||</span> <span class="n">token</span> <span class="p">==</span> <span class="s">""</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="k">await</span> <span class="n">Response</span><span class="p">.</span><span class="nf">WriteAsync</span><span class="p">(</span><span class="n">token</span><span class="p">);</span>
        <span class="k">await</span> <span class="n">Response</span><span class="p">.</span><span class="n">Body</span><span class="p">.</span><span class="nf">FlushAsync</span><span class="p">();</span> <span class="c1">// Flush the response stream to send the token immediately</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h4 id="ai-response-generation">AI Response Generation</h4>

<p>Finally, in the <code class="language-plaintext highlighter-rouge">GenerateAiResponse</code> method, we call the generator and continuously produce the next token in the sequence:</p>

<div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">private</span> <span class="k">async</span> <span class="n">IAsyncEnumerable</span><span class="p">&lt;</span><span class="kt">string</span><span class="p">&gt;</span> <span class="nf">GenerateAiResponse</span><span class="p">(</span><span class="kt">string</span> <span class="n">fullPrompt</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">var</span> <span class="n">tokens</span> <span class="p">=</span> <span class="n">_tokenizer</span><span class="p">.</span><span class="nf">Encode</span><span class="p">(</span><span class="n">fullPrompt</span><span class="p">);</span>
    <span class="kt">var</span> <span class="n">generatorParams</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">GeneratorParams</span><span class="p">(</span><span class="n">_model</span><span class="p">);</span>
    <span class="n">generatorParams</span><span class="p">.</span><span class="nf">SetSearchOption</span><span class="p">(</span><span class="s">"max_length"</span><span class="p">,</span> <span class="m">4096</span><span class="p">);</span>
    <span class="n">generatorParams</span><span class="p">.</span><span class="nf">SetInputSequences</span><span class="p">(</span><span class="n">tokens</span><span class="p">);</span>
    <span class="kt">var</span> <span class="n">generator</span> <span class="p">=</span> <span class="k">new</span> <span class="nf">Generator</span><span class="p">(</span><span class="n">_model</span><span class="p">,</span> <span class="n">generatorParams</span><span class="p">);</span>
    <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"Generator created."</span><span class="p">);</span>

    <span class="k">while</span> <span class="p">(!</span><span class="n">generator</span><span class="p">.</span><span class="nf">IsDone</span><span class="p">())</span>
    <span class="p">{</span>
        <span class="n">generator</span><span class="p">.</span><span class="nf">ComputeLogits</span><span class="p">();</span>
        <span class="n">generator</span><span class="p">.</span><span class="nf">GenerateNextToken</span><span class="p">();</span>
        <span class="kt">var</span> <span class="n">output</span> <span class="p">=</span> <span class="nf">GetOutputTokens</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">_tokenizer</span><span class="p">);</span>
        <span class="n">Console</span><span class="p">.</span><span class="nf">WriteLine</span><span class="p">(</span><span class="s">"Generating next token..."</span><span class="p">+</span><span class="n">output</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">output</span> <span class="p">==</span> <span class="k">null</span> <span class="p">||</span> <span class="n">output</span><span class="p">==</span><span class="s">""</span><span class="p">)</span>
        <span class="p">{</span>
            <span class="k">break</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="k">yield</span> <span class="k">return</span> <span class="n">output</span><span class="p">;</span> <span class="c1">// Yield each token as it's generated</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><strong>Note: This demo focuses on the basic setup and functionality. We haven’t applied any optimizations to the response generation process. As a result, sometimes the output might be incorrect. For more advanced scenarios, consider tuning ONNX runtime parameters like <code class="language-plaintext highlighter-rouge">top_k</code>, <code class="language-plaintext highlighter-rouge">top_p</code>, <code class="language-plaintext highlighter-rouge">temperature</code>, and others to refine the model’s output. Refer to the documentation <a href="https://onnxruntime.ai/docs/genai/reference/config.html">here</a></strong></p>

<h4 id="creating-the-container-image-for-the-backend">Creating the container image for the backend</h4>

<p>Once the backend code is ready, the final step is to containerize the application for deployment. We’ve included a Dockerfile in the repository, which you can find <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/phi3-vector/phi3-vector-api/Dockerfile">here</a>. This Dockerfile is set up to build and run the .NET backend in a container.</p>

<p>To containerize the backend, navigate to the <code class="language-plaintext highlighter-rouge">phi3-vector-api</code> directory and build the Docker image:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">-t</span> your-dockerhub-username/phi3-vector-api:latest <span class="nb">.</span>
</code></pre></div></div>

<p>Replace <code class="language-plaintext highlighter-rouge">your-registry-url</code> with the name of your container registry, such as Azure Container Registry, Docker Hub, or a private registry.</p>

<p>After building the image, push it to your container registry:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker push your-registry-url/phi3-vector-api:latest
</code></pre></div></div>

<h3 id="creating-the-frontend-chat-application">Creating the Frontend Chat Application</h3>

<p>To enable interaction with the backend API, we’ll set up a simple Python Flask app as the chat interface. One of the advantages of the Sidecar pattern is that it allows you to run multiple containers using different languages and frameworks side by side, seamlessly integrating them into a single application.</p>

<h4 id="flask-chat-application">Flask Chat Application</h4>

<p>Navigate to the <code class="language-plaintext highlighter-rouge">flask-chat-app</code> folder where the code resides in <code class="language-plaintext highlighter-rouge">app.py</code>. This method sends user input to the backend API and streams the response in real-time:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate</span><span class="p">():</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="n">API_URL</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">input_text</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Time taken: </span><span class="si">{</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="p">.</span><span class="nf">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">chunk</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">yield</span> <span class="sh">'</span><span class="s">Error: </span><span class="sh">'</span> <span class="o">+</span> <span class="n">response</span><span class="p">.</span><span class="n">text</span>

    <span class="k">return</span> <span class="nc">Response</span><span class="p">(</span><span class="nf">generate</span><span class="p">(),</span> <span class="n">content_type</span><span class="o">=</span><span class="sh">'</span><span class="s">text/plain</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="containerizing-the-flask-application">Containerizing the Flask Application</h4>

<p>To containerize the app, use the provided <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/phi3-vector/flask-chat-app/Dockerfile">Dockerfile</a> in the <code class="language-plaintext highlighter-rouge">flask-chat-app</code> directory. Build and push the image with:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">-t</span> your-registry-url/flask-chat-app:latest <span class="nb">.</span>
docker push your-registry-url/flask-chat-app:latest
</code></pre></div></div>

<p><strong>Note: The Sidecar feature is currently enabled for custom-container scenarios on Linux App Service, with plans to support code-based scenarios soon.</strong></p>

<h2 id="deploying-the-application-to-linux-app-service">Deploying the Application to Linux App Service</h2>

<ol>
  <li>
    <p><strong>Create a New Linux Web App in Azure</strong></p>

    <p>Create a new Linux Web App from the portal and choose the options for Container and Linux.</p>

    <p><img src="/AppService/media/2024/07/CreateWebApp.jpg" alt="Create web app" /></p>

    <p>On the Container tab, make sure that Sidecar support is Enabled.</p>

    <p>Specify the details of your application image (Flask app).</p>

    <p><img src="/AppService/media/2024/07/AddContainer.jpg" alt="Create web app" /></p>

    <p><em>Make sure to set the port to 5000</em></p>

    <p><em>Note: We strongly recommend enabling <a href="https://learn.microsoft.com/azure/app-service/overview-managed-identity?tabs=portal%2Chttp">Managed Identity</a> for your Azure resources.</em></p>
  </li>
  <li>
    <p><strong>Add Phi-3 Vector API Sidecar</strong></p>

    <p>Go to the Deployment Center for your application and add a sidecar container.</p>

    <p><img src="/AppService/media/2024/09/vector-api.jpg" alt="Add Phi-3 Vector API sidecar" /></p>

    <p><em>Make sure to set the port to 5045</em></p>

    <p>This <a href="https://learn.microsoft.com/azure/app-service/tutorial-custom-container-sidecar">document</a> tells you how to add sidecars, step-by-step.</p>
  </li>
  <li>
    <p><strong>Verify the deployment</strong></p>

    <p>Once your deployment is complete, you can browse to your application URL and see the chat frontend.</p>

    <p><img src="/AppService/media/2024/09/phi-vector-output.jpg" alt="Website output" /></p>

    <p><em>Note: Since we are deploying a language model, please be aware that the application might take a little longer to start up the first time. This delay is due to the initial setup and loading of the Phi-3 model, which ensures that it is ready to handle requests efficiently. Subsequent startups should be faster once the model is properly initialized.</em></p>
  </li>
</ol>

<h2 id="in-summary">In Summary</h2>

<p>In this blog, we demonstrated how to implement a Retrieval-Augmented Generation (RAG) system using the Phi-3 ONNX Runtime on Linux App Service with the Sidecar pattern. We walked through setting up the .NET backend to load markdown files into an in-memory vector database, generating responses using the Phi-3 model. We then built a Python Flask frontend to interact with the backend, showcasing how different languages and frameworks can seamlessly work together using Sidecars. Finally, we containerized both the backend and frontend for deployment.</p>

<p>We’d love to hear about your experiences and what you’re building with the Sidecar feature. Your feedback is crucial as we continue to expand its capabilities and add more scenarios.</p>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[In our previous post, “Phi-3 ONNX: Leveraging the Power of ONNX Runtime to Run SLM on CPU”, we explored how to deploy and run the Phi-3 ONNX Runtime model on Linux App Service, enabling sophisticated language model capabilities without the need for a GPU. Building on that foundation, this blog post will take you through the implementation of Retrieval-Augmented Generation (RAG) using local resources.]]></summary></entry><entry><title type="html">Optimizing SLM with ONNX Runtime: Phi-3 on CPU with Sidecars for App Service</title><link href="https://azure.github.io/AppService/2024/08/19/Phi-3-ONNX.html" rel="alternate" type="text/html" title="Optimizing SLM with ONNX Runtime: Phi-3 on CPU with Sidecars for App Service" /><published>2024-08-19T00:00:00+00:00</published><updated>2024-08-19T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/08/19/Phi-3-ONNX</id><content type="html" xml:base="https://azure.github.io/AppService/2024/08/19/Phi-3-ONNX.html"><![CDATA[<p>In my previous blog post, <a href="https://azure.github.io/AppService/2024/08/05/Using-SLM-with-Sidecar.html">Using SLM with Sidecar</a>, we explored the integration of Small Language Models (SLM), specifically Phi-3, with the Sidecar pattern on Linux App Service. This approach offered a flexible and scalable solution to enhance application functionality, particularly in scenarios requiring lightweight language models.</p>

<p>Building on that foundation, this post delves into the next step: leveraging the power of the ONNX Runtime to run Phi-3 on CPU. ONNX Runtime is a high-performance inference engine for deploying machine learning models in production. It offers several advantages, such as cross-platform support, optimized performance for a variety of hardware, and the ability to run models efficiently on CPUs without the need for specialized GPUs.</p>

<p>By using Phi-3 with ONNX Runtime on CPU, you can achieve a more accessible and cost-effective deployment, making it an excellent choice for applications where GPU resources are limited or unnecessary. In this post, we’ll walk through the process of setting up Phi-3 with ONNX Runtime and demonstrate how it can be integrated with the Sidecar pattern on Linux App Service.</p>

<h2 id="prerequisites">Prerequisites</h2>

<ul>
  <li><a href="https://www.docker.com/products/docker-desktop/">Docker Desktop</a></li>
  <li><a href="https://code.visualstudio.com/Download">Visual Studio Code</a></li>
  <li><a href="https://www.python.org/downloads/">Python 3.9 or higher</a></li>
  <li>The code for this project is available <a href="https://github.com/Azure-Samples/sidecar-samples/tree/main/phi-3">here</a></li>
</ul>

<h2 id="creating-the-container-image-for-phi-3-onnx-runtime">Creating the Container Image for Phi-3 ONNX Runtime</h2>

<p>In this section, we’ll walk through the process of creating a container image for the <a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-onnx">Phi-3 model using ONNX Runtime on CPU</a>. This image will be ready to serve the model via an API and can be deployed as a sidecar on Linux App Service.</p>

<ol>
  <li>
    <p><strong>Set Up the Project Directory</strong>
 First, create a directory to hold all the files related to this project. You can name it something like phi-3-sidecar:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">mkdir </span>phi-3-sidecar
 <span class="nb">cd </span>phi-3-sidecar
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Download the Hugging Face CLI</strong>
 To download the Phi-3 model, you’ll need the Hugging Face CLI. If you don’t have it installed yet, you can do so using pip:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> pip <span class="nb">install </span>huggingface-hub
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Download the CPU Model</strong>
 Use the Hugging Face CLI to download the specific version of the Phi-3 model optimized for CPU:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> huggingface-cli download microsoft/Phi-3-mini-4k-instruct-onnx <span class="nt">--include</span> cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4/<span class="k">*</span> <span class="nt">--local-dir</span> <span class="nb">.</span>
</code></pre></div>    </div>

    <p>This command downloads the necessary model files into your project directory.</p>
  </li>
  <li>
    <p><strong>Create the model_api.py File</strong>
 Next, create a Python script named model_api.py to serve the model via an API. This script will handle incoming requests and use the ONNX Runtime to generate output. This is a sample <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/phi-3/phi-3-sidecar/model_api.py">model_api.py</a> that you can use.</p>

    <p>These are the key parts of the code</p>
    <ul>
      <li>
        <p>Load the model and the tokenizer</p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">model_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">/app/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4</span><span class="sh">"</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">og</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>

  <span class="c1"># Load the tokenizer from onnxruntime_genai
</span>  <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">og</span><span class="p">.</span><span class="nc">Tokenizer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
  <span class="n">tokenizer_stream</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">create_stream</span><span class="p">()</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>Preprocess the input text and pass it to the model</p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">input_text</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">input_text</span>

  <span class="n">chat_template</span> <span class="o">=</span> <span class="sh">'</span><span class="s">&lt;|user|&gt;</span><span class="se">\n</span><span class="s">{input} &lt;|end|&gt;</span><span class="se">\n</span><span class="s">&lt;|assistant|&gt;</span><span class="sh">'</span>
  <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">chat_template</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">input_text</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Prompt</span><span class="sh">"</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
  <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

  <span class="n">params</span> <span class="o">=</span> <span class="n">og</span><span class="p">.</span><span class="nc">GeneratorParams</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
  <span class="n">params</span><span class="p">.</span><span class="nf">set_search_options</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>
  <span class="n">params</span><span class="p">.</span><span class="nf">set_search_options</span><span class="p">(</span><span class="n">do_sample</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="n">params</span><span class="p">.</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_tokens</span>

  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Input tokens</span><span class="sh">"</span><span class="p">,</span> <span class="n">input_tokens</span><span class="p">)</span>
  <span class="n">generator</span> <span class="o">=</span> <span class="n">og</span><span class="p">.</span><span class="nc">Generator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>Generate the output tokens and return it as a streaming response</p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">def</span> <span class="nf">token_generator</span><span class="p">():</span>
      <span class="n">generated_text</span> <span class="o">=</span> <span class="sh">""</span>
      <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Starting generator</span><span class="sh">"</span><span class="p">,</span> <span class="n">generator</span><span class="p">.</span><span class="nf">is_done</span><span class="p">())</span>
      <span class="k">while</span> <span class="ow">not</span> <span class="n">generator</span><span class="p">.</span><span class="nf">is_done</span><span class="p">():</span>
          <span class="n">generator</span><span class="p">.</span><span class="nf">compute_logits</span><span class="p">()</span>
          <span class="n">generator</span><span class="p">.</span><span class="nf">generate_next_token</span><span class="p">()</span>
            
          <span class="n">new_token</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="nf">get_next_tokens</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
          <span class="n">generated_text</span> <span class="o">+=</span> <span class="n">tokenizer_stream</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">new_token</span><span class="p">)</span>
          <span class="k">yield</span> <span class="n">tokenizer_stream</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">new_token</span><span class="p">)</span> 
                
  <span class="k">return</span> <span class="nc">StreamingResponse</span><span class="p">(</span><span class="nf">token_generator</span><span class="p">(),</span> <span class="n">media_type</span><span class="o">=</span><span class="sh">"</span><span class="s">text/plain</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Create a Dockerfile</strong>
 To containerize the application, you’ll need a Dockerfile. This file will define the environment, dependencies, and steps required to run the model_api.py script inside a container. A sample Dockerfile can be found <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/phi-3/phi-3-sidecar/Dockerfile">here</a>.</p>

    <p>The Dockerfile typically includes:</p>

    <ul>
      <li><em>Base Image:</em> A lightweight Python image is used as the base.</li>
      <li><em>Dependencies:</em> Instructions to install necessary Python libraries and ONNX Runtime.</li>
      <li><em>Copying Files:</em> The model files and the model_api.py script are copied into the container.</li>
      <li><em>Run command:</em> The container exposes a port and runs the model_api.py script when started.</li>
    </ul>
  </li>
  <li>
    <p><strong>Build and Push the Image</strong>
 Finally, build the Docker image and push it to your preferred container registry. Here’s how you can do it:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c"># Build the Docker image</span>
 docker build <span class="nt">-t</span> phi-3-sidecar:latest <span class="nb">.</span>

 <span class="c"># Tag the image for your container registry</span>
 docker tag phi-3-sidecar:latest &lt;registry-name&gt;/phi-3-sidecar:latest

 <span class="c"># Push the image to your registry</span>
 docker push &lt;registry-name&gt;/phi-3-sidecar:latest
</code></pre></div>    </div>

    <p>Replace <code class="language-plaintext highlighter-rouge">registry-name</code> with the name of your container registry, such as Azure Container Registry, Docker Hub, or a private registry.</p>
  </li>
</ol>

<h2 id="setting-up-the-chat-application">Setting Up the Chat Application</h2>

<p>Now that we’ve created the container image for our Phi-3 ONNX Runtime model, the next step is to set up a chat application that leverages this model to generate responses. This application will serve as the main app, calling the SLM image running as a sidecar to handle user inputs.</p>

<ol>
  <li>
    <p><strong>Implementing the Chat Application</strong>
 The core of our chat application is a Python script, <code class="language-plaintext highlighter-rouge">app.py</code>, which handles the communication between the user and the SLM. Here’s how we set it up:</p>

    <ul>
      <li>
        <p><em>Calling the Sidecar:</em> The application communicates with the SLM sidecar using the localhost URL. The API endpoint /predict is called to process the input text and generate responses.</p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">API_URL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">http://localhost:8000/predict</span><span class="sh">"</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p><em>Streaming the Response:</em> The response from the SLM is streamed back to the user. This approach ensures that the user receives a continuous stream of text, enhancing the interaction experience.</p>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">Copy</span> <span class="n">code</span>
  <span class="k">def</span> <span class="nf">generate</span><span class="p">():</span>
      <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>  <span class="c1"># Start the timer
</span>      <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="n">API_URL</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">input_text</span><span class="sh">"</span><span class="p">:</span> <span class="n">input_text</span><span class="p">},</span> <span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>  <span class="c1"># End the timer
</span>
      <span class="n">time_taken</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>  <span class="c1"># Calculate the time taken
</span>      <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Time taken for API response: </span><span class="si">{</span><span class="n">time_taken</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># Print the time taken
</span>
      <span class="k">if</span> <span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
          <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="p">.</span><span class="nf">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
              <span class="k">if</span> <span class="n">chunk</span><span class="p">:</span>
                  <span class="k">yield</span> <span class="n">chunk</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
          <span class="k">yield</span> <span class="sh">'</span><span class="s">Error: </span><span class="sh">'</span> <span class="o">+</span> <span class="n">response</span><span class="p">.</span><span class="n">text</span>

  <span class="k">return</span> <span class="nc">Response</span><span class="p">(</span><span class="nf">generate</span><span class="p">(),</span> <span class="n">content_type</span><span class="o">=</span><span class="sh">'</span><span class="s">text/plain</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div>        </div>
      </li>
    </ul>

    <p>This code starts a timer when the request is made, logs the time taken for the API to respond, and then streams the response to the client. If the API call is successful, the chunks of the response are decoded and sent to the user. If there’s an error, it returns the error message.</p>

    <p>The full implementation of this script can be found <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/phi-3/main-app/app.py">here</a>.</p>
  </li>
  <li>
    <p><strong>Containerizing Your Python Application</strong>
 We’ll containerize our chat application by creating a Dockerfile in the root directory of the project. This Dockerfile will set up the environment, install dependencies, and define how the application is run inside a container.</p>

    <p><em>Note: The Sidecar feature is currently enabled for custom-container scenarios for Linux App Service. We are working on enabling it for code scenarios as well. We will update the blog soon for the code-based web applications</em></p>

    <p>The Dockerfile for this project is available <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/phi-3/main-app/Dockerfile">here</a>.</p>
  </li>
  <li>
    <p><strong>Build and Push the Docker Image</strong>
 Once the Dockerfile is ready, you can build the Docker image and push it to your preferred container registry. Here are the commands:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c"># Build the Docker image</span>
 docker build <span class="nt">-t</span> &lt;your-registry&gt;/&lt;your-image-name&gt;:&lt;tag&gt; <span class="nb">.</span>

 <span class="c"># Push the image to your registry</span>
 docker push &lt;your-registry&gt;/&lt;your-image-name&gt;:&lt;tag&gt;
</code></pre></div>    </div>

    <p>Replace <code class="language-plaintext highlighter-rouge">&lt;your-registry&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;your-image-name&gt;</code>, and <code class="language-plaintext highlighter-rouge">&lt;tag&gt;</code> with the appropriate values for your container registry, image name, and version tag.</p>
  </li>
</ol>

<h2 id="deploying-the-application-to-linux-app-service">Deploying the Application to Linux App Service</h2>

<ol>
  <li>
    <p><strong>Create a New Linux Web App in Azure</strong></p>

    <p>Create a new Linux Web App from the portal and choose the options for Container and Linux.</p>

    <p><img src="/AppService/media/2024/07/CreateWebApp.jpg" alt="Create web app" /></p>

    <p>On the Container tab, make sure that Sidecar support is Enabled.</p>

    <p>Specify the details of your application image.</p>

    <p><img src="/AppService/media/2024/07/AddContainer.jpg" alt="Create web app" /></p>

    <p><em>Note: We strongly recommend enabling <a href="https://learn.microsoft.com/azure/app-service/overview-managed-identity?tabs=portal%2Chttp">Managed Identity</a> for your Azure resources.</em></p>
  </li>
  <li>
    <p><strong>Add Phi-3 ONNX Sidecar</strong></p>

    <p>Go to the Deployment Center for your application and add a sidecar container.</p>

    <p><img src="/AppService/media/2024/08/phi-onnx-sidecar.jpg" alt="Add Phi-3 sidecar" /></p>

    <p>This <a href="https://learn.microsoft.com/azure/app-service/tutorial-custom-container-sidecar">document</a> tells you how to add sidecars, step-by-step.</p>
  </li>
  <li>
    <p><strong>Verify the deployment</strong></p>

    <p>Once your deployment is complete, you can browse to your application URL and see the chat frontend.</p>

    <p><img src="/AppService/media/2024/08/phi-onnx-output.jpg" alt="Website output" /></p>

    <p><em>Note: Since we are deploying a language model, please be aware that the application might take a little longer to start up the first time. This delay is due to the initial setup and loading of the Phi-3 model, which ensures that it is ready to handle requests efficiently. Subsequent startups should be faster once the model is properly initialized.</em></p>
  </li>
</ol>

<h2 id="summary">Summary</h2>

<p>In this blog post, we extended our exploration of Small Language Models (SLMs) by focusing on the integration of Phi-3 ONNX Runtime for CPU with the Sidecar pattern on Linux App Service. This powerful combination offers a robust scenario for building intelligent applications that can efficiently run on CPU, making advanced AI capabilities more accessible and cost-effective.</p>

<p>We are actively working on more AI scenarios for Azure App Service and would love to hear what you are building. Your feedback and ideas are invaluable as we continue to explore the possibilities of AI and cloud-based deployments.</p>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[In my previous blog post, Using SLM with Sidecar, we explored the integration of Small Language Models (SLM), specifically Phi-3, with the Sidecar pattern on Linux App Service. This approach offered a flexible and scalable solution to enhance application functionality, particularly in scenarios requiring lightweight language models.]]></summary></entry><entry><title type="html">.NET 9 Preview 6 now available on App Service</title><link href="https://azure.github.io/AppService/2024/08/19/net-9-preview-6-available-on-app-service.html" rel="alternate" type="text/html" title=".NET 9 Preview 6 now available on App Service" /><published>2024-08-19T00:00:00+00:00</published><updated>2024-08-19T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/08/19/net-9-preview-6-available-on-app-service</id><content type="html" xml:base="https://azure.github.io/AppService/2024/08/19/net-9-preview-6-available-on-app-service.html"><![CDATA[<p>We are happy to announce that App Service now supports apps targeting <a href="https://devblogs.microsoft.com/dotnet/dotnet-9-preview-6/">.NET 9 Preview 6</a> across all public regions on Linux App Service Plans. Deployment is underway, and it will be available for Windows App Service plans soon.</p>

<p>Want to get started with .NET 9? Follow these:</p>

<ol>
  <li><a href="https://devblogs.microsoft.com/dotnet/dotnet-9-preview-6/">Learn more about .NET 9 Preview 6</a></li>
  <li><a href="https://learn.microsoft.com/aspnet/core/release-notes/aspnetcore-9.0?view=aspnetcore-8.0">ASP.NET Core in .NET 9</a></li>
  <li><a href="https://learn.microsoft.com/dotnet/core/whats-new/dotnet-9/overview">What’s new in .NET 9</a></li>
  <li><a href="https://docs.microsoft.com/azure/app-service/quickstart-dotnetcore?tabs=net60&amp;pivots=development-environment-vs">Deploy a .NET app to App Service</a></li>
</ol>

<p>Mark your calendars for the <a href="https://www.youtube.com/watch?v=Vj2ujuj5_Vo">App Service Community Standup on September 4th, 2024, at 10:00 AM PST</a>, where we’ll dive into .NET 9 and App Configuration!</p>

<p>You can also follow us on twitter for more updates and news: <a href="https://twitter.com/AzAppService/">@AzAppService</a></p>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[We are happy to announce that App Service now supports apps targeting .NET 9 Preview 6 across all public regions on Linux App Service Plans. Deployment is underway, and it will be available for Windows App Service plans soon.]]></summary></entry><entry><title type="html">Azure App Service Community Standup: Integrating Datadog with Linux App Service using Sidecars</title><link href="https://azure.github.io/AppService/2024/08/08/App-Service-Community-Standup.html" rel="alternate" type="text/html" title="Azure App Service Community Standup: Integrating Datadog with Linux App Service using Sidecars" /><published>2024-08-08T00:00:00+00:00</published><updated>2024-08-08T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/08/08/App-Service-Community-Standup</id><content type="html" xml:base="https://azure.github.io/AppService/2024/08/08/App-Service-Community-Standup.html"><![CDATA[<p>Watch the latest Azure App Service Community Standup on Integrating Datadog with Linux App Service using Sidecars.</p>

<p><a href="https://www.youtube.com/watch?v=xSrDUDLknhQ"><img src="https://img.youtube.com/vi/xSrDUDLknhQ/hqdefault.jpg" alt="Azure App Service Community Standup" /></a></p>

<p>For more information on Datadog and Sidecar patterns on App Service, check out the following resources:</p>

<ul>
  <li>
    <p><a href="https://www.datadoghq.com/private-beta/aas-sidecar/">Azure App Service (AAS) - Sidecar Support</a></p>
  </li>
  <li>
    <p><a href="https://docs.datadoghq.com/serverless/guide/azure_app_service_linux_sidecar/">Instrument Azure App Service - Linux Containers with Sidecar Pattern</a></p>
  </li>
  <li>
    <p><a href="https://azure.github.io/AppService/2024/07/26/Using-Datadog-with-Sidecar.html">A Step-by-Step Guide to Datadog Integration with Linux App Service via Sidecars</a></p>
  </li>
</ul>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[Watch the latest Azure App Service Community Standup on Integrating Datadog with Linux App Service using Sidecars.]]></summary></entry><entry><title type="html">Building Smarter Apps: Integrating Phi-3 SLM with Linux App Service</title><link href="https://azure.github.io/AppService/2024/08/05/Using-SLM-with-Sidecar.html" rel="alternate" type="text/html" title="Building Smarter Apps: Integrating Phi-3 SLM with Linux App Service" /><published>2024-08-05T00:00:00+00:00</published><updated>2024-08-05T00:00:00+00:00</updated><id>https://azure.github.io/AppService/2024/08/05/Using-SLM-with-Sidecar</id><content type="html" xml:base="https://azure.github.io/AppService/2024/08/05/Using-SLM-with-Sidecar.html"><![CDATA[<p>In our ongoing series exploring the integration of various sidecar scenarios with Linux App Service, we delve into an exciting new domain—building AI applications. Following our previous discussion on leveraging <a href="https://azure.github.io/AppService/2024/07/19/Using-Redis-with-Sidecar.html">Redis as a sidecar</a>, we now turn our focus to using Small Language Models (SLMs) to enhance the capabilities of your web applications.</p>

<p>In this post, we will demonstrate how to deploy <a href="https://azure.microsoft.com/blog/introducing-phi-3-redefining-whats-possible-with-slms/">Phi-3</a>, a powerful SLM, as a sidecar to your Linux App Service. SLMs offer numerous advantages for web applications, including:</p>

<ol>
  <li><strong>More Lightweight &amp; Efficient</strong>: This makes them more suitable for situations where computational resources are limited or where real-time inference is required.</li>
  <li><strong>More Accessible</strong>: SLMs lower the barrier to entry for people who want to experiment with language models. Anyone who has access to a laptop or mobile device can train and deploy an SLM, whereas training and deploying an LLM would likely require expensive cloud services or specialized hardware.</li>
  <li><strong>Domain-Specific Adaptation</strong>: You can fine-tune SLMs to specific industry domains, such as legal, finance, or e-commerce, to improve performance and accuracy. This domain-specific adaptation allows the model to understand specialized terminology and context better, leading to more accurate results and insights. By tailoring SLMs to their specific use cases, organizations can unlock new opportunities for innovation and differentiation in their respective industries.</li>
  <li><strong>More Secure</strong>: Since SLMs have smaller codebases and fewer potential surfaces for security breaches, they are also less vulnerable to malicious attacks.</li>
  <li><strong>Better for the Environment</strong>: SLMs use less energy and memory than LLMs, which makes them more environmentally friendly and sustainable. They also have smaller footprints and faster inference times, which makes them more suitable for edge computing and real-time applications.</li>
</ol>

<h2 id="setting-up-the-application">Setting Up the Application</h2>

<p>For our sample application, we are creating a simple Node.js chat app. You can clone this <a href="https://github.com/Azure-Samples/sidecar-samples/tree/main/slm-using-ollama/slm-using-ollama">repo</a> if you would like to follow along.</p>

<p>This app will serve as the front end for interacting with the Phi-3 Small Language Model (SLM) running as a sidecar. You can find the code of the app <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/slm-using-ollama/slm-using-ollama/webapp/app.js">here</a>.</p>

<p>This is the main part of the code.</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">app</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="dl">"</span><span class="s2">/api/generate</span><span class="dl">"</span><span class="p">,</span> <span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
    <span class="nx">request</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="dl">'</span><span class="s1">http://localhost:11434/api/generate</span><span class="dl">'</span><span class="p">,</span> <span class="p">{</span> <span class="na">json</span> <span class="p">:</span> <span class="p">{</span>
        <span class="dl">"</span><span class="s2">model</span><span class="dl">"</span><span class="p">:</span> <span class="dl">"</span><span class="s2">phi3</span><span class="dl">"</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">prompt</span><span class="dl">"</span><span class="p">:</span> <span class="nx">req</span><span class="p">.</span><span class="nx">body</span><span class="p">.</span><span class="nx">prompt</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">stream</span><span class="dl">"</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
        <span class="dl">"</span><span class="s2">options</span><span class="dl">"</span><span class="p">:</span> <span class="p">{</span>
          <span class="dl">"</span><span class="s2">num_keep</span><span class="dl">"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">num_predict</span><span class="dl">"</span><span class="p">:</span> <span class="mi">150</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">seed</span><span class="dl">"</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">top_k</span><span class="dl">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">top_p</span><span class="dl">"</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">tfs_z</span><span class="dl">"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">typical_p</span><span class="dl">"</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">repeat_last_n</span><span class="dl">"</span><span class="p">:</span> <span class="mi">33</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">temperature</span><span class="dl">"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">repeat_penalty</span><span class="dl">"</span><span class="p">:</span> <span class="mf">1.2</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">presence_penalty</span><span class="dl">"</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">frequency_penalty</span><span class="dl">"</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">mirostat</span><span class="dl">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">mirostat_tau</span><span class="dl">"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">mirostat_eta</span><span class="dl">"</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">penalize_newline</span><span class="dl">"</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
          <span class="dl">"</span><span class="s2">stop</span><span class="dl">"</span><span class="p">:</span> <span class="p">[</span><span class="dl">"</span><span class="s2">&lt;*end*&gt;</span><span class="dl">"</span><span class="p">],</span>
          <span class="dl">"</span><span class="s2">num_thread</span><span class="dl">"</span><span class="p">:</span> <span class="mi">8</span>
        <span class="p">}</span>
    <span class="p">}}</span>
    <span class="p">,</span> <span class="p">(</span><span class="nx">error</span><span class="p">,</span> <span class="nx">response</span><span class="p">,</span> <span class="nx">body</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
        <span class="k">if </span><span class="p">(</span><span class="nx">error</span><span class="p">)</span> <span class="p">{</span>
          <span class="nx">console</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="nx">error</span><span class="p">);</span>
          <span class="k">return</span><span class="p">;</span>
        <span class="p">}</span>
        
        <span class="nx">res</span><span class="p">.</span><span class="nf">json</span><span class="p">(</span><span class="nx">body</span><span class="p">);</span>
    <span class="p">})</span>
<span class="p">});</span>
</code></pre></div></div>

<ul>
  <li>This route handles POST requests to the /api/generate endpoint.</li>
  <li>It forwards the request to the Phi-3 SLM API running locally on port 11434.</li>
  <li>The request body includes the model configuration and prompt, along with various options for generating the response.</li>
  <li>The server sends the response from the SLM API back to the client.</li>
</ul>

<h2 id="building-your-application-container-images">Building your application container images</h2>

<p><strong>Prerequisites:</strong> Ensure you have <a href="https://www.docker.com/products/docker-desktop/">Docker Desktop</a> installed.</p>

<ol>
  <li>
    <p>To get started, you’ll need to containerize your Node.js application. This <a href="https://docs.docker.com/language/nodejs/containerize/">article</a> walks you through the process step by step.</p>

    <p><em>Note: The Sidecar feature is currently enabled for custom-container scenarios for Linux App Service. We are working on enabling it for code scenarios as well. We will update the blog soon for the code-based web applications</em></p>

    <p>The Dockerfile for this project is <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/slm-using-ollama/slm-using-ollama/webapp/Dockerfile">here</a>.</p>

    <p>Build the image and push it to your preferred container registry, such as Azure Container Registry, Docker Hub, or a private registry.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     docker build <span class="nt">-t</span> &lt;your-registry&gt;/&lt;your-image-name&gt;:&lt;tag&gt; <span class="nb">.</span>
     docker push &lt;your-registry&gt;/&lt;your-image-name&gt;:&lt;tag&gt;
</code></pre></div>    </div>
  </li>
  <li>
    <p>Build the Phi-3 container image as well and push it to your container registry. You can use this <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/slm-using-ollama/slm-using-ollama/slm/Dockerfile">Dockerfile</a>.</p>

    <p>For our Phi-3 images, we are also using a <a href="https://github.com/Azure-Samples/sidecar-samples/blob/main/slm-using-ollama/slm-using-ollama/slm/startup.sh">startup file</a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c">#!/usr/bin/env bash</span>
    
 <span class="c"># Start Ollama in the background</span>
 ollama serve &amp;
 <span class="nb">sleep </span>5
    
 <span class="c"># Pull and run phi3</span>
 ollama pull phi3
    
 <span class="c"># Restart ollama and run it in to foreground.</span>
 pkill <span class="nt">-f</span> <span class="s2">"ollama"</span>
 ollama serve
</code></pre></div>    </div>

    <p>This startup file performs the following actions:</p>
    <ul>
      <li>Starts the Ollama server in the background and waits for 5 seconds to ensure it is running.</li>
      <li>Pulls the Phi-3 model using Ollama.</li>
      <li>Restarts the Ollama server by killing the existing background process and then running it in the foreground to ensure the Phi-3 model is loaded and ready for use.</li>
    </ul>
  </li>
</ol>

<h2 id="deploying-the-application-to-linux-app-service">Deploying the Application to Linux App Service</h2>

<ol>
  <li>
    <p><strong>Create a New Linux Web App in Azure</strong></p>

    <p>Create a new Linux Web App from the portal and choose the options for Container and Linux.
 <img src="/AppService/media/2024/07/CreateWebApp.jpg" alt="Create web app" /></p>

    <p>On the Container tab, make sure that Sidecar support is Enabled.</p>

    <p>Specify the details of your application image.
 <img src="/AppService/media/2024/07/AddContainer.jpg" alt="Create web app" /></p>

    <p><em>Note: We strongly recommend enabling <a href="https://learn.microsoft.com/azure/app-service/overview-managed-identity?tabs=portal%2Chttp">Managed Identity</a> for your Azure resources.</em></p>
  </li>
  <li>
    <p><strong>Add Phi-3 Sidecar</strong></p>

    <p>Go to the Deployment Center for your application and add a sidecar container.
 <img src="/AppService/media/2024/08/phi-sidecar.jpg" alt="Add Phi-3 sidecar" /></p>

    <p>This <a href="https://learn.microsoft.com/azure/app-service/tutorial-custom-container-sidecar">document</a> tells you how to add sidecars, step-by-step.</p>
  </li>
  <li>
    <p><strong>Verify the deployment</strong></p>

    <p>Once your deployment is complete, you can browse to your application URL and see the chat frontend.</p>

    <p><img src="/AppService/media/2024/08/phi-output.jpg" alt="Website output" /></p>

    <p><em>Note: Since we are deploying a language model, please be aware that the application might take a little longer to start up the first time. This delay is due to the initial setup and loading of the Phi-3 model, which ensures that it is ready to handle requests efficiently. Subsequent startups should be faster once the model is properly initialized.</em></p>
  </li>
</ol>

<h2 id="summary">Summary</h2>

<p>In this blog post, we explored how to deploy Phi-3, a Small Language Model (SLM), as a sidecar on Linux App Service to add AI capabilities in your web applications. We discussed the benefits of using SLMs, such as being more lightweight, accessible, and secure, as well as their suitability for domain-specific adaptation and environmental sustainability. We also walked through the setup of a simple Node.js chat application that interacts with Phi-3, providing a practical example of how to integrate SLMs into your projects.</p>

<p>For more examples of Phi-3, feel free to explore this <a href="https://github.com/microsoft/Phi-3CookBook">repository</a>.</p>

<p>While we’ll continue to build and share more exciting sidecar scenarios, we can’t wait to see the amazing applications you create with these powerful features!</p>]]></content><author><name>Azure App Service</name></author><summary type="html"><![CDATA[In our ongoing series exploring the integration of various sidecar scenarios with Linux App Service, we delve into an exciting new domain—building AI applications. Following our previous discussion on leveraging Redis as a sidecar, we now turn our focus to using Small Language Models (SLMs) to enhance the capabilities of your web applications.]]></summary></entry></feed>